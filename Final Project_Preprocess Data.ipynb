{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprosess Products Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv('producto_tabla.csv')\n",
    "\n",
    "# Extract short name for the NombreProducto col\n",
    "products['short_name'] = products.NombreProducto.str.extract('^(\\D*)', expand=False)\n",
    "# Extract brand for NombreProducto col\n",
    "products['brand'] = products.NombreProducto.str.extract('^.+\\s(\\D+) \\d+$', expand=False)\n",
    "# Extract weight from NombreProducto col\n",
    "w = products.NombreProducto.str.extract('(\\d+)(Kg|g)', expand=True)\n",
    "products['weight'] = w[0].astype('float')*w[1].map({'Kg':1000, 'g':1})\n",
    "# Extract the # of pieces from NombreProducto col\n",
    "products['pieces'] =  products.NombreProducto.str.extract('(\\d+)p ', expand=False).astype('float')\n",
    "# Shorten the product name using spanish stopwords\n",
    "products['short_name_processed'] = (products['short_name'].map(lambda x: \" \"\n",
    "                                    .join([i for i in x.lower()\n",
    "                                    .split() if i not in stopwords.words(\"spanish\")])))\n",
    "\n",
    "# Keep shortening the product name \n",
    "stemmer = SnowballStemmer(\"spanish\")\n",
    "products['short_name_processed'] = (products['short_name_processed'].map(lambda x: \" \"\n",
    "                                    .join([stemmer.stem(i) for i in x.lower().split()])))\n",
    "\n",
    "# Drop cols\n",
    "products = products.drop(columns = ['NombreProducto','short_name'],axis = 1)\n",
    "# Rename cols\n",
    "products = products.rename(columns = {'short_name_processed':'Producto_name'})\n",
    "products = products.rename(columns = {'Producto_ID':'Producto_ID'})\n",
    "# Reorder cols\n",
    "products = products[['Producto_ID','Producto_name','brand','weight','pieces']]\n",
    "products[:10]\n",
    "\n",
    "# Add a col called \"weight_per_piece\"\n",
    "products['weight_per_piece'] = products['weight']/products['pieces']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprosess Clients Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(935362, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients = pd.read_csv('cliente_tabla.csv')\n",
    "clients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>NombreCliente</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SIN NOMBRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>OXXO XINANTECATL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SIN NOMBRE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>EL MORENO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SDN SER  DE ALIM  CUERPO SA CIA  DE INT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cliente_ID                            NombreCliente\n",
       "0           0                               SIN NOMBRE\n",
       "1           1                         OXXO XINANTECATL\n",
       "2           2                               SIN NOMBRE\n",
       "3           3                                EL MORENO\n",
       "4           4  SDN SER  DE ALIM  CUERPO SA CIA  DE INT"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(930500, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicate ids\n",
    "duplicate_ids = clients.duplicated(subset = 'Cliente_ID')    \n",
    "clients = clients[duplicate_ids == False]    \n",
    "clients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307009\n"
     ]
    }
   ],
   "source": [
    "# number of unique clients names\n",
    "print(str(len(clients['NombreCliente'].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Different ids can have the same clients name\n",
    "\n",
    "As we can see, there are a lot of unique clients names. Let's try to find some similarities and features between them and group them by those similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NombreCliente</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>227063</th>\n",
       "      <td>NO IDENTIFICADO</td>\n",
       "      <td>281670</td>\n",
       "      <td>30.270822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178995</th>\n",
       "      <td>LUPITA</td>\n",
       "      <td>4863</td>\n",
       "      <td>0.522622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203200</th>\n",
       "      <td>MARY</td>\n",
       "      <td>3016</td>\n",
       "      <td>0.324127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163963</th>\n",
       "      <td>LA PASADITA</td>\n",
       "      <td>2426</td>\n",
       "      <td>0.260720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165834</th>\n",
       "      <td>LA VENTANITA</td>\n",
       "      <td>2267</td>\n",
       "      <td>0.243632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162357</th>\n",
       "      <td>LA GUADALUPANA</td>\n",
       "      <td>1299</td>\n",
       "      <td>0.139602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265099</th>\n",
       "      <td>ROSY</td>\n",
       "      <td>1245</td>\n",
       "      <td>0.133799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20891</th>\n",
       "      <td>ALEX</td>\n",
       "      <td>1242</td>\n",
       "      <td>0.133477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120794</th>\n",
       "      <td>GABY</td>\n",
       "      <td>1238</td>\n",
       "      <td>0.133047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161465</th>\n",
       "      <td>LA ESCONDIDA</td>\n",
       "      <td>1216</td>\n",
       "      <td>0.130682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NombreCliente  Frequency    Percent\n",
       "227063  NO IDENTIFICADO     281670  30.270822\n",
       "178995           LUPITA       4863   0.522622\n",
       "203200             MARY       3016   0.324127\n",
       "163963      LA PASADITA       2426   0.260720\n",
       "165834     LA VENTANITA       2267   0.243632\n",
       "162357   LA GUADALUPANA       1299   0.139602\n",
       "265099             ROSY       1245   0.133799\n",
       "20891              ALEX       1242   0.133477\n",
       "120794             GABY       1238   0.133047\n",
       "161465     LA ESCONDIDA       1216   0.130682"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# frequencies of clients names\n",
    "\n",
    "# count how many times the same name showed up using groupby\n",
    "common_client_names = pd.DataFrame({'Frequency': clients.groupby(['NombreCliente'])['NombreCliente']\n",
    "                                    .count()}).reset_index()\n",
    "\n",
    "common_client_names['Percent'] = 100.0 * common_client_names['Frequency'] / common_client_names['Frequency'].sum()\n",
    "    \n",
    "common_client_names = common_client_names.sort_values(by = 'Frequency', ascending = False)\n",
    "common_client_names[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Except NO IDENTIFICADO (Non-identified), the names occur the most are colloquial names of individual clients like Mary, Rosy, Alex, or Gaby and the others are companies with stopwords in Spanish like LA and EL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>NombreCliente</th>\n",
       "      <th>Client_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SIN NOMBRE</td>\n",
       "      <td>sin nombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>OXXO XINANTECATL</td>\n",
       "      <td>oxxo xinantecatl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SIN NOMBRE</td>\n",
       "      <td>sin nombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>EL MORENO</td>\n",
       "      <td>el moreno</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SDN SER  DE ALIM  CUERPO SA CIA  DE INT</td>\n",
       "      <td>sdn ser  de alim  cuerpo sa cia  de int</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cliente_ID                            NombreCliente  \\\n",
       "0           0                               SIN NOMBRE   \n",
       "1           1                         OXXO XINANTECATL   \n",
       "2           2                               SIN NOMBRE   \n",
       "3           3                                EL MORENO   \n",
       "4           4  SDN SER  DE ALIM  CUERPO SA CIA  DE INT   \n",
       "\n",
       "                               Client_Type  \n",
       "0                               sin nombre  \n",
       "1                         oxxo xinantecatl  \n",
       "2                               sin nombre  \n",
       "3                                el moreno  \n",
       "4  sdn ser  de alim  cuerpo sa cia  de int  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries for handling text data\n",
    "\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stemmer = SnowballStemmer('spanish')\n",
    "\n",
    "# Create copy of NombreCliente named Client_Type\n",
    "# Convert to lowercase\n",
    "clients['Client_Type'] = clients['NombreCliente'].str.lower()\n",
    "clients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sin nombre',\n",
       " 'oxxo xinantecatl',\n",
       " 'sin nombre',\n",
       " 'el moreno',\n",
       " 'sdn ser de alim cuerpo sa cia de int',\n",
       " 'la vaquita',\n",
       " 'lupita',\n",
       " 'i m el guero',\n",
       " 'mini super los lupes',\n",
       " 'super kompras micro colon']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split words in Client_Type variable\n",
    "nombre_split = clients['Client_Type'].str.split()\n",
    "    \n",
    "# Remove empty spaces from names\n",
    "nombre_no_spaces = [\" \".join(x) for x in nombre_split]  \n",
    "\n",
    "# Remove non-letters and replace numbers with 'NUM'\n",
    "nombre_no_spaces = [re.sub('[^A-Za-z0-9]+', ' ', x) for x in nombre_no_spaces]   \n",
    "nombre_no_spaces = [re.sub('[0-9]+', 'NUM', x) for x in nombre_no_spaces]\n",
    "\n",
    "nombre_no_spaces[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sin', 'nombr'],\n",
       " ['oxxo', 'xinantecatl'],\n",
       " ['sin', 'nombr'],\n",
       " ['el', 'moren'],\n",
       " ['sdn', 'ser', 'de', 'alim', 'cuerpo', 'sa', 'cia', 'de', 'int'],\n",
       " ['la', 'vaquit'],\n",
       " ['lupit'],\n",
       " ['i', 'm', 'el', 'guer'],\n",
       " ['mini', 'super', 'los', 'lup'],\n",
       " ['super', 'kompras', 'micro', 'colon']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stem and tokenize words \n",
    "\n",
    "nombre_stem = [stemmer.stem(x) for x in nombre_no_spaces]\n",
    "nombre_tokenized = [word_tokenize(x) for x in nombre_stem]\n",
    "nombre_tokenized[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nombre',\n",
       " 'oxxo xinantecatl',\n",
       " 'nombre',\n",
       " 'moreno',\n",
       " 'sdn ser alim cuerpo sa cia int',\n",
       " 'vaquita',\n",
       " 'lupita',\n",
       " 'i m guero',\n",
       " 'mini super lupes',\n",
       " 'super kompras micro colon',\n",
       " 'lonja mercantil',\n",
       " 'farmacia nicolas san juan',\n",
       " 'papeleria catala',\n",
       " 'elena',\n",
       " 'casa trino',\n",
       " 'fma035947 bimbo sa cv',\n",
       " 'joys',\n",
       " 'marco',\n",
       " 'lupes ii',\n",
       " 'tiendita',\n",
       " 'fma026712 tecnoautomotriz atlacomulco s',\n",
       " 'abarrotes ivan',\n",
       " 'garnica',\n",
       " 'fma026709 bucirus bladas mexico sa',\n",
       " 'fma026248 proveedora norte',\n",
       " 'carrosita',\n",
       " 'bodega comercial mexicana toluca',\n",
       " 'marquez',\n",
       " 'fma033097 automotriz mexicana s c',\n",
       " 'jose aguilar catalan']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove stop words\n",
    "\n",
    "nombre_tokenized = [word_tokenize(x) for x in clients.ix[:, 'Client_Type']]\n",
    "stops = set(stopwords.words(\"spanish\"))\n",
    "nombre_cleaned = [[w for w in i if not w in stops] for i in nombre_tokenized] \n",
    "nombre_cleaned = [\" \".join(x) for x in nombre_cleaned]  \n",
    "nombre_cleaned[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 'company' category, we found that there are some obvious subcategories. For example, OXXO (convenience store), abarrotes (grocery store), and super (super market) are 3 subcategories.\n",
    "\n",
    "Thus, we perform a client classification as follow.\n",
    "\n",
    "Cited from https://www.kaggle.com/abbysobh/grupo-bimbo-inventory-demand/classifying-client-type-using-client-names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_client_features(clients):\n",
    "    \"\"\" Creates new variable 'Client_Type' by categorizing NombreCliente\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create new feature\n",
    "    clients = clients.copy()\n",
    "    clients['Client_Type'] = clients.ix[:, 'NombreCliente']    \n",
    "    \n",
    "    # Convert to all UPPER-CASE\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].str.upper()\n",
    "    \n",
    "    # Known Large Company / Special Group Types\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].str.replace('.*REMISION.*','Consignment')\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].replace(['.*WAL MART.*','.*SAMS CLUB.*'],'Walmart', regex=True)\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].str.replace('.*OXXO.*','Oxxo Store')\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].str.replace('.*CONASUPO.*','Govt Store')\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].str.replace('.*BIMBO.*','Bimbo Store')\n",
    "    \n",
    "    # Term search for assortment of words picked from looking at their frequencies\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].replace(['.*COLEG.*','.*UNIV.*','.*ESCU.*','.*INSTI.*',\\\n",
    "                                                        '.*PREPAR.*'],'School', regex=True)\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].str.replace('.*PUESTO.*','Post')\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].replace(['.*FARMA.*','.*HOSPITAL.*','.*CLINI.*'],'Hospital/Pharmacy', regex=True)\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].replace(['.*CAFE.*','.*CREMERIA.*','.*DULCERIA.*',\\\n",
    "                                                        '.*REST.*','.*BURGER.*','.*TACO.*', '.*TORTA.*',\\\n",
    "                                                        '.*TAQUER.*','.*HOT DOG.*',\\\n",
    "                                                        '.*COMEDOR.*', '.*ERIA.*','.*BURGU.*'],'Eatery', regex=True)\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].str.replace('.*SUPER.*','Supermarket')\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].replace(['.*COMERCIAL.*','.*BODEGA.*','.*DEPOSITO.*',\\\n",
    "                                                            '.*ABARROTES.*','.*MERCADO.*','.*CAMBIO.*',\\\n",
    "                                                        '.*MARKET.*','.*MART .*','.*MINI .*',\\\n",
    "                                                        '.*PLAZA.*','.*MISC.*','.*ELEVEN.*','.*EXP.*',\\\n",
    "                                                         '.*SNACK.*', '.*PAPELERIA.*', '.*CARNICERIA.*',\\\n",
    "                                                         '.*LOCAL.*','.*COMODIN.*','.*PROVIDENCIA.*'\n",
    "                                                        ],'General Market/Mart'\\\n",
    "                                                       , regex=True)                                                   \n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].replace(['.*VERDU.*','.*FRUT.*'],'Fresh Market', regex=True)\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].replace(['.*HOTEL.*','.*MOTEL.*'],'Hotel', regex=True)    \n",
    " \n",
    "    # Filter participles\n",
    "    clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].replace([\n",
    "            '.*LA .*','.*EL .*','.*DE .*','.*LOS .*','.*DEL .*','.*Y .*', '.*SAN .*', '.*SANTA .*',\\\n",
    "            '.*AG .*','.*LAS .*','.*MI .*','.*MA .*', '.*II.*', '.*[0-9]+.*'\\\n",
    "                ],'Small Franchise', regex=True)\n",
    "               \n",
    "    # Everything else bucketed into 'Individual'\n",
    "    def filter_remaining(clients):\n",
    "        def function_word(data):\n",
    "            # Avoid the single-words created so far by checking for upper-case\n",
    "            if (data.isupper()) and (data != \"NO IDENTIFICADO\"): \n",
    "                return 'Individual'\n",
    "            else:\n",
    "                return data\n",
    "        clients.ix[:, 'Client_Type'] = clients.ix[:, 'Client_Type'].map(function_word)\n",
    "    filter_remaining(clients)\n",
    "    \n",
    "    # Return data\n",
    "    return clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cliente_ID</th>\n",
       "      <th>NombreCliente</th>\n",
       "      <th>Client_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SIN NOMBRE</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>OXXO XINANTECATL</td>\n",
       "      <td>Oxxo Store</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SIN NOMBRE</td>\n",
       "      <td>Individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>EL MORENO</td>\n",
       "      <td>Small Franchise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SDN SER  DE ALIM  CUERPO SA CIA  DE INT</td>\n",
       "      <td>Small Franchise</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cliente_ID                            NombreCliente      Client_Type\n",
       "0           0                               SIN NOMBRE       Individual\n",
       "1           1                         OXXO XINANTECATL       Oxxo Store\n",
       "2           2                               SIN NOMBRE       Individual\n",
       "3           3                                EL MORENO  Small Franchise\n",
       "4           4  SDN SER  DE ALIM  CUERPO SA CIA  DE INT  Small Franchise"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients = create_client_features(clients)\n",
    "clients.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate our new categories' frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clients['Client_Type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Client_Type</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Percent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Individual</td>\n",
       "      <td>351908</td>\n",
       "      <td>37.819237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NO IDENTIFICADO</td>\n",
       "      <td>281670</td>\n",
       "      <td>30.270822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Small Franchise</td>\n",
       "      <td>158357</td>\n",
       "      <td>17.018485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>General Market/Mart</td>\n",
       "      <td>65516</td>\n",
       "      <td>7.040946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eatery</td>\n",
       "      <td>30277</td>\n",
       "      <td>3.253842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Supermarket</td>\n",
       "      <td>15911</td>\n",
       "      <td>1.709941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Oxxo Store</td>\n",
       "      <td>9276</td>\n",
       "      <td>0.996883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hospital/Pharmacy</td>\n",
       "      <td>5693</td>\n",
       "      <td>0.611822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>School</td>\n",
       "      <td>5562</td>\n",
       "      <td>0.597743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Post</td>\n",
       "      <td>2658</td>\n",
       "      <td>0.285653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hotel</td>\n",
       "      <td>1104</td>\n",
       "      <td>0.118646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fresh Market</td>\n",
       "      <td>1060</td>\n",
       "      <td>0.113917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Govt Store</td>\n",
       "      <td>958</td>\n",
       "      <td>0.102955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bimbo Store</td>\n",
       "      <td>319</td>\n",
       "      <td>0.034283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>217</td>\n",
       "      <td>0.023321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consignment</td>\n",
       "      <td>14</td>\n",
       "      <td>0.001505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Client_Type  Frequency    Percent\n",
       "8            Individual     351908  37.819237\n",
       "9       NO IDENTIFICADO     281670  30.270822\n",
       "13      Small Franchise     158357  17.018485\n",
       "4   General Market/Mart      65516   7.040946\n",
       "2                Eatery      30277   3.253842\n",
       "14          Supermarket      15911   1.709941\n",
       "10           Oxxo Store       9276   0.996883\n",
       "6     Hospital/Pharmacy       5693   0.611822\n",
       "12               School       5562   0.597743\n",
       "11                 Post       2658   0.285653\n",
       "7                 Hotel       1104   0.118646\n",
       "3          Fresh Market       1060   0.113917\n",
       "5            Govt Store        958   0.102955\n",
       "0           Bimbo Store        319   0.034283\n",
       "15              Walmart        217   0.023321\n",
       "1           Consignment         14   0.001505"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_client_types = pd.DataFrame({'Frequency': clients.groupby(['Client_Type'])['Client_Type']\n",
    "                                    .count()}).reset_index()\n",
    "\n",
    "common_client_types['Percent'] = 100.0 * common_client_types['Frequency'] / common_client_types['Frequency'].sum()\n",
    "common_client_types = common_client_types.sort_values(by = 'Frequency', ascending = False)\n",
    "common_client_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprosessing training/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because Venta_uni_hoy, Venta_hoy, Dev_uni_proxima, and Dev_proxima are highly correlated with Demanda_uni_equil (Adjusted Demand), and they are used in the calculation to derive Adjusted Demand, we choose to remove them from our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns = ['Venta_uni_hoy','Venta_hoy','Dev_uni_proxima','Dev_proxima'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the product_name to our training set using Merge function \n",
    "train = train.merge(products, on ='Producto_ID',how='inner')\n",
    "\n",
    "# Attach the clients_type to our training set using Merge function\n",
    "train = train.merge(clients, on = 'Cliente_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "# Attach the product_name to our test set using Merge function \n",
    "test = test.merge(products, on ='Producto_ID',how='inner')\n",
    "\n",
    "# Attach the clients_type to our test set using Merge function\n",
    "test = test.merge(clients, on = 'Cliente_ID', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add time series lag variables to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_time_series_features(train, test):\n",
    "    \"\"\" Takes train and test data as inputs. \n",
    "        Adds lagged adjusted demand variables to the data periods t-2, t-3, t-4, and t-5.\n",
    "        Returns modified data. \n",
    "    \"\"\"\n",
    "    # Add lagged time series variables to train/test\n",
    "    # Groups by (Cliente_ID, Producto_ID)\n",
    "    for i in range(1, 6):\n",
    "        # Add tminus to train\n",
    "        columns = ['Semana', 'Cliente_ID', 'Producto_ID', 'Demanda_uni_equil']       \n",
    "        train_tminus = train.ix[:, columns]\n",
    "        train_tminus = train_tminus.rename(columns = {'Demanda_uni_equil': 'Demanda_uni_equil_tminus' + str(i)})\n",
    "        train_tminus['Semana'] = train_tminus['Semana'] + i\n",
    "        columns.remove('Demanda_uni_equil')\n",
    "        train_tminus = pd.DataFrame({'Demanda_uni_equil_tminus' + str(i) : train_tminus.groupby(columns)['Demanda_uni_equil_tminus' + str(i)].mean()}).reset_index()         \n",
    "        \n",
    "        train = train.merge(train_tminus, how = 'left', on = ['Semana', 'Cliente_ID', 'Producto_ID'])   \n",
    "        train['Demanda_uni_equil_tminus' + str(i)] = train['Demanda_uni_equil_tminus' + str(i)].astype(np.float16)\n",
    "                \n",
    "        # Add tminus for Semana == 10\n",
    "        columns = ['Semana', 'Cliente_ID', 'Producto_ID', 'Demanda_uni_equil_tminus' + str(i)]\n",
    "        test = test.merge(train_tminus.ix[train_tminus['Semana'] == 10, columns], how = 'left', on = ['Semana', 'Cliente_ID', 'Producto_ID'])\n",
    "        test['Demanda_uni_equil_tminus' + str(i)] = test['Demanda_uni_equil_tminus' + str(i)].astype(np.float16)     \n",
    "    \n",
    "        # Add tminus for Semana == 11\n",
    "        if(i != 1):\n",
    "            test = test.merge(train_tminus.ix[train_tminus['Semana'] == 11, columns], how = 'left', on = ['Semana', 'Cliente_ID', 'Producto_ID']) \n",
    "            test = test.rename(columns = {'Demanda_uni_equil_tminus' + str(i) + '_x': 'Demanda_uni_equil_tminus' + str(i)})\n",
    "            test.ix[test['Semana'] == 11, 'Demanda_uni_equil_tminus' + str(i)] = test.ix[test['Semana'] == 11, 'Demanda_uni_equil_tminus' + str(i) + '_y']\n",
    "            test = test.drop('Demanda_uni_equil_tminus' + str(i) + '_y', axis = 1)\n",
    "            test['Demanda_uni_equil_tminus' + str(i)] = test['Demanda_uni_equil_tminus' + str(i)].astype(np.float16)\n",
    "        \n",
    "        # Replace null values with zeros\n",
    "        train.ix[train['Demanda_uni_equil_tminus' + str(i)].isnull(), 'Demanda_uni_equil_tminus' + str(i)] = 0\n",
    "        test.ix[test['Demanda_uni_equil_tminus' + str(i)].isnull(), 'Demanda_uni_equil_tminus' + str(i)] = 0    \n",
    "            \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = add_time_series_features(train, test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add mean weekly frequency variables for categorical id variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: this step increases our model's accuracy rate by dealing with id variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_mean_freq_by_id(train, test):\n",
    "    \"\"\" Takes train and test data as inputs. \n",
    "        Adds mean of frequencies of different id features by week (semana).\n",
    "        Returns train and test data.\n",
    "    \"\"\"\n",
    "    columns =  ['Agencia_ID', 'Canal_ID', 'Ruta_SAK', 'Cliente_ID', 'Producto_ID', 'Producto_name', 'Client_Type'] \n",
    "    for column in columns:\n",
    "        \n",
    "        # Create mean of weekly id counts\n",
    "        train_counts = pd.DataFrame({column + '_count' : train[[column, 'Semana']].groupby([column, 'Semana']).size()}).reset_index()\n",
    "        test_counts = pd.DataFrame({column + '_count' : test[[column, 'Semana']].groupby([column, 'Semana']).size()}).reset_index()\n",
    "        counts = train_counts.append(test_counts)      \n",
    "        counts = pd.DataFrame({column + '_count' : counts.groupby([column])[column + '_count'].mean()}).reset_index()\n",
    "        counts[column + '_count'] = counts[column + '_count'].astype(np.float32) \n",
    "\n",
    "        # Merge with train and test data\n",
    "        train = train.merge(counts, how = 'left', on = column)    \n",
    "        test = test.merge(counts, how = 'left', on = column)  \n",
    "        \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = add_mean_freq_by_id(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode categorical variables¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "def encode_labels(train, test, threshold): \n",
    "    \"\"\" Converts categorical features to integers in train and test data.\n",
    "        Groups values in categorical features appearing less than threshold into a separate category.\n",
    "        Returns train and test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Identify columns for label encoding\n",
    "    columns = list(train.columns[train.dtypes == 'object'])\n",
    "       \n",
    "    # Return data if no columns identified   \n",
    "    if(len(columns) == 0):\n",
    "        return train, test\n",
    "       \n",
    "    # Transform columns\n",
    "    for column in columns: \n",
    "        \n",
    "        # Filter data\n",
    "        classes = train[column].unique()\n",
    "        counts = train[column].value_counts()\n",
    "        counts_classes = counts.index[counts <= threshold]\n",
    "        \n",
    "        # Set classes under threshold to 'identific'\n",
    "        train.ix[train[column].isin(counts_classes), column] = 'identific'        \n",
    "        test.ix[test[column].isin(counts_classes), column] = 'identific'          \n",
    "        \n",
    "        # Classes in test not in train sent to 'identific'\n",
    "        test.ix[test[column].isin(classes) == False, column] = 'identific'\n",
    "        \n",
    "        # Perform label encoding\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(train[column])\n",
    "        train[column] = le.transform(train[column]).astype(np.uint32)\n",
    "        test[column] = le.transform(test[column]).astype(np.uint32)\n",
    "        \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = encode_labels(train, test, threshold = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove date before Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[train['Semana'] > 5]  \n",
    "train = train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reorder columns in data¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "            'Semana', 'Agencia_ID', 'Canal_ID', 'Ruta_SAK', 'Cliente_ID', 'Producto_ID'\n",
    "            , 'Client_Type', 'Producto_name' \n",
    "            , 'weight', 'pieces', 'weight_per_piece'\n",
    "            , 'Demanda_uni_equil', 'Demanda_uni_equil_tminus1', 'Demanda_uni_equil_tminus2'\n",
    "            , 'Demanda_uni_equil_tminus3', 'Demanda_uni_equil_tminus4', 'Demanda_uni_equil_tminus5'\n",
    "            , 'Agencia_ID_count', 'Canal_ID_count', 'Ruta_SAK_count', 'Cliente_ID_count'\n",
    "            , 'Producto_ID_count', 'Client_Type_count'\n",
    "          ]\n",
    "\n",
    "train = train.reindex(columns = columns)\n",
    "columns.remove('Demanda_uni_equil')\n",
    "test = test.reindex(columns = columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write data to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"train_modified.csv\", index = False, header = True)\n",
    "test.to_csv(\"test_modified.csv\", index = False, header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
